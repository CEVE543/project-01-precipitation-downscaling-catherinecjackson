---
title: "Project 1"
subtitle: "Downscaling: Comparison of Quantile-Quantile Mapping and Lab 06 Methodology"
jupyter: julia-1.9
date: 2023-11-13
author: "Catherine Jackson (ccj3)"

number-sections: true
code-annotations: hover

kind: "Project"
Module: "1"
categories:
    - "Module 3"
    - "Projects"

format:
    html: 
        toc-depth: 3
    docx: 
        toc: true
        toc-depth: 3
        fig-format: png
---

# Intro

## Statistical and Dynamical Downscaling
Global Climate Models, also referred to as GCMs, are incredibly valuable tools in that they can capture large scale climate dynamics (e.g. future greenhouse gas concentration over the entire Earth).  Furthermore, many of these phenomena must be studied at a global scale.  However, there are limitations to GCMs.  Primarily, given the large scale analysis, grid cells and computation points for these models are actually quite large.  This leads to problems when trying to study local phenomena, such as the climate of a specific city or region.  This is when downscaling must be used.  There are two types of downscaling: Dynamical and Statistical. 

### Dynamical Downscaling
This type of downscaling uses a Regional Climate Model (RCM) which takes in the output of a GCM as a boundary condition.  Then, RCM use these boundary conditions and physical principles to generate higher resolution local climate.  However, thse are computationally expensive.

### Statistical Downscaling
Statistical Downscaling is another common method dependent on the availability of local weather data, such as precipitation.  A statistical relationship is developed between the historic observed climate data and the output of the climate model for the same historical period.  Then, this statistical relationship is used to downscale the climate model output to the local scale.  This can be combined with bias correction and adjustment to improve the accuracy of the downscaled data.

For this project, we will be using statistical downscaling in that we will attempt to determine a relationship between global predictors like temperature and pressure and local precipitation.  Then, we will use this relationship to downscale the precipitation data.

### Statistical Downscaling Methods
Statistical Downscaling, SD, consists of a identified historical period (calibration) used to analyze the predictor/predictand relationship.  This relationship is then applied to predictors from the GCMs to get the local climate projections. 

:::{.callout-note}
Sources include the Copernicus Climate Change Service (C3S), National Oceanic and Atmospheric Administration (NOAA), Evaluaation of statistical downscaling methods for climate change projections over Spain: Present conditions with perfect predictors (2021).
:::

# Project
For this project, I will be conducting a slightly different analysis than others in the class.  As I proposed to Dr. Doss-Gollin, I want to undertake a deep dive into a Julia based Downscaling Package, analyze the methods and algorithms used, apply it to 

# Packages
```{julia}
using Plots
using StatsBase
using StatsPlots
using Distributions
using Statistics
using CDSAPI
using NCDatasets
using StatsBase: shuffle
using NCDatasets
using RainFARM
using DataFrames
```

# Downloading Data
```{julia}
precip_tx = NCDataset("data/precip_tx.nc")
temp_2015 = NCDataset("data/raw/2m_temperature_2015.nc")
temp_2016 = NCDataset("data/raw/2m_temperature_2016.nc")
temp_2017 = NCDataset("data/raw/2m_temperature_2017.nc")
temp_2018 = NCDataset("data/raw/2m_temperature_2018.nc")
temp_2019 = NCDataset("data/raw/2m_temperature_2019.nc")
temp_2020 = NCDataset("data/raw/2m_temperature_2020.nc")
press_2015 = NCDataset("data/raw/500hPa_geopotential_2015.nc")
press_2016 = NCDataset("data/raw/500hPa_geopotential_2016.nc")
press_2017 = NCDataset("data/raw/500hPa_geopotential_2017.nc")
press_2018 = NCDataset("data/raw/500hPa_geopotential_2018.nc")
press_2019 = NCDataset("data/raw/500hPa_geopotential_2019.nc")
press_2020 = NCDataset("data/raw/500hPa_geopotential_2020.nc")

display(precip_tx)
```

# Data Preprocessing
``` {julia}
# Remove all of the missing values from the precipitation data
# This is necessary for the RainFARM Package
# Remove all of the missing values from the precipitation data
# This is necessary for the RainFARM Package
precip_tx_p = precip_tx["precip"]
#test_precip_tx_p = precip_tx_p[:, :, 1:10]
#precip_tx_no_missing = test_precip_tx_p[.!ismissing.(test_precip_tx_p)]

```

``` {julia}
# combine all temp files so there is a continuous time variable
# select the first 8760 hours of the 2016 data t2m
# 2016 is a leap year so it has 8784 hours
temp_2016 = temp_2016[:, :, 1:8760];
# create an empty matrix with dimensions 66, 27, 34680
temp_2015to2018                    = zeros(66, 27, 34680)
temp_2015to2018[:, :, 1:8760]      = temp_2015
temp_2015to2018[:, :, 8761:17340]  = temp_2016
temp_2015to2018[:, :, 17341:26010] = temp_2017
temp_2015to2018[:, :, 26011:34680] = temp_2018
temp15to18                         = temp_2015to2018
```

```{julia}
using RainFARM
using DataFrames
# Assume that you want to replace missing values with 0.0
default_value = 0.0

# Replace missing values in precip_tx_p with the default_value
r = coalesce.(precip_tx_p, default_value)
slope = 1;
nf = 5;
downscaled_precip_tx = rainfarm(r, slope, nf)
```

```{julia}
# plot one frame of the downscaled_precip_tx
timeframe = 7
downheatmap = heatmap(downscaled_precip_tx[:, :, timeframe])
origheatmap = heatmap(precip_tx_p[:, :, timeframe])
plot(downheatmap, origheatmap, layout = (1, 2), legend = false)
```

```{julia}

# Quantile Quantile Mapping
Quantile-Quantile Mapping, or Q-Q Mapping, can be used to downscale climate data. This method is used to adjust the distribution of a variable to match the distribution of another variable. In this case, we are using Q-Q Mapping to adjust the distribution of the precipitation data to match the observed temperature data.  Temperature data tends to be smoother and more reliable than precipitation data, so we are using the temperature data as a reference to adjust the precipitation data.

## Methodology
The Q-Q Mapping methodology is as follows:
1. Calculate the cumulative distribution function (CDF) of the observed temperature data and the CDF of the precipitation data.
    We know that the CDF returns the probabilities of X being less than or equal to some value x.
    $$
    Pr(X \leq x) = F(x)
    $$
2. Calculate the inverse of the CDF of the observed temperature data and the inverse of the CDF of the precipitation data.
    The inverse CDF can also be called the quantile function, and it can take this CDF and give us values for the quantiles we want!  It can be represented with the following equation:
    $$
    F^{-1}(p) = x
    $$
    It can also be conceptualized as choosing a value you want on the y axis (e.g. the 0.9 quantile or 90% probability of being less than the value x), tracing over to the graph until you hit the CDF, and then moving down to the x axis to find your value of x that corresponds to the 0.9 quantile.
3. Use the inverse of the CDF of the observed temperature data to transform the precipitation data to match the observed temperature data.


## Implementation
The Q-Q Mapping methodology was implemented in Julia using the following code:

```{julia}

precipitation = [2,6,2,3,4,5,8,5,6,6,7,13,9,12,9,10,10,10,11,11,11,12,12,12,13]
temperature = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
function qqmap(precipitation::AbstractVector{<:Real}, temperature::AbstractVector{<:Real})
    cdf_precipitation = ecdf(precipitation)
    cdf_temperature = ecdf(temperature)
    adjusted_precip_data = [quantile(temperature, cdf_precipitation(x)) for x in precipitation]
    return adjusted_precip_data
end
newprecipitation = qqmap(precipitation, temperature)
compplot = plot(precipitation)
compplot = plot!(newprecipitation)
```

# Lab 06: PCA and kNN


## Methodology
The Lab 06 methodology is as follows:
1. Calculate the principal components of the observed temperature data.
2. Utilize the k-Nearest Neighbors algorithm to find the k nearest neighbors of the observed temperature data.
3. Use the k nearest neighbors of the observed temperature data to predict the precipitation data.

## Implementation
The Lab 06 methodology was implemented in Julia using the following code:

```{julia}
# Assuming `precip` is your precipitation data variable
# Dimensions: lon × lat × time

# Create an empty array to store data without missing values
cleaned_precip_tx = Float32[]
# Loop through the time dimension
for t = 1:8760
    # Extract a 2D slice at time t
    slice = precip_tx[:, :, t]
    # Filter out missing values from the 2D slice
    #cleaned_slice = filter(x -> !ismissing(x), slice)
    # Append the cleaned slice to the cleaned_precip array
    #append!(cleaned_precip_tx, cleaned_slice)
end

# Calculate the new dimensions after removing missing values
#new_lon, new_lat, new_time = size(precip_tx)

# Reshape the cleaned data to match the original dimensions
#cleaned_precip_tx = reshape(cleaned_precip_tx, new_lon, new_lat, new_time)

# Now, `cleaned_precip` contains your data with missing values removed
```